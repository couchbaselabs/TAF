epengine.documentkeys.DocumentKeysTests:
    # Mad-hatter's Durability tests applicable for magma
    #Covers tests with different key types
    test_dockey_whitespace_data_ops,num_items=1000,replicas=2,nodes_init=4,GROUP=P1;durability
    test_dockey_binary_data_ops,num_items=1000,replicas=2,nodes_init=4,GROUP=P1;durability
    test_dockey_unicode_data_ops,num_items=1000,replicas=2,nodes_init=4,GROUP=P1;durability
    test_dockey_whitespace_views,num_items=1000,replicas=2,nodes_init=4,GROUP=P1;not_for_ephemeral_buckets;durability
    test_dockey_binary_views,num_items=1000,replicas=2,nodes_init=4,GROUP=P1;not_for_ephemeral_buckets;durability
    test_dockey_unicode_views,num_items=1000,replicas=2,nodes_init=4,GROUP=P1;not_for_ephemeral_buckets;durability

    # Max key_length tests
    test_dockey_whitespace_data_ops,num_items=250000,replicas=2,nodes_init=4,key_length=241,GROUP=P0;durability;windows
    test_dockey_binary_data_ops,num_items=250000,replicas=2,nodes_init=4,key_length=241,GROUP=P0;durability;windows
    test_dockey_unicode_data_ops,num_items=250000,replicas=2,nodes_init=4,key_length=30,GROUP=P0;durability;windows

    # Single vbucket test
    test_dockey_whitespace_data_ops,num_items=10000,replicas=2,nodes_init=4,key_length=241,target_vbucket=10,GROUP=P0;durability


magma.magma_basic_crud.BasicCrudTests:
    #Covers tests with different key sizes and mix key sizes,
    #adding docs in descending order, ascending order and random fashion

    #200 MB per vbucket, 128 vBuckets, total documents will be 25000000
    test_basic_create_read,num_items=5000000,nodes_init=4,key_size=240,sdk_timeout=60,vbuckets=128,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=4,mix_key_size=True,key_size=20,sdk_timeout=60,vbuckets=128,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=4,random_key=True,key_size=22,sdk_timeout=60,vbuckets=128,deep_copy=True,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=4,key_size=20,randomize_doc_size=True,sdk_timeout=60,vbuckets=128,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=4,rev_write=True,sdk_timeout=60,vbuckets=128,deep_copy=True,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=4,rev_read=True,sdk_timeout=60,vbuckets=128,deep_copy=True,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=4,rev_write=True,rev_read=True,sdk_timeout=60,vbuckets=128,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=4,key_size=22,sdk_timeout=60,vbuckets=128,GROUP=P1
    test_basic_create_read,num_items=5000000,nodes_init=4,key_size=12,sdk_timeout=60,vbuckets=128,GROUP=P1

    #100 MB per vbucket,512vbuckets, total documents will be 50000000 and 25000000 respectively in below two cases
    test_basic_create_read,num_items=10000000,nodes_init=4,key_size=240,sdk_timeout=60,vbuckets=512,GROUP=P0
    test_basic_create_read,num_items=10000000,nodes_init=4,key_size=20,randomize_doc_size=True,sdk_timeout=60,vbuckets=512,GROUP=P1
    test_basic_create_read,num_items=5000000,nodes_init=4,sdk_timeout=60,doc_size=0,vbuckets=512,GROUP=P1

    #200 MB per vbucket, 1024vbuckets, total documents will be 200000000
    test_basic_create_read,num_items=40000000,nodes_init=4,key_size=22,sdk_timeout=60,fragmentation=50,GROUP=P1
    test_basic_create_read,num_items=40000000,nodes_init=4,mix_key_size=True,key_size=20,sdk_timeout=60,GROUP=P2
    test_basic_create_read,num_items=40000000,nodes_init=4,randomize_doc_size=True,key_size=20,sdk_timeout=60,GROUP=P2
    test_basic_create_read,num_items=40000000,nodes_init=4,key_size=22,sdk_timeout=60,fragmentation=30,GROUP=P2
    test_basic_create_read,num_items=40000000,nodes_init=4,key_size=22,sdk_timeout=60,fragmentation=80,GROUP=P2
    test_basic_create_read,num_items=40000000,nodes_init=4,random_key=True,key_size=22,sdk_timeout=60,deep_copy=True,GROUP=P2
    test_basic_create_read,num_items=40000000,nodes_init=4,rev_write=True,sdk_timeout=60,deep_copy=True,GROUP=P2
    test_basic_create_read,num_items=40000000,nodes_init=4,rev_read=True,sdk_timeout=60,deep_copy=True,GROUP=P2
    test_basic_create_read,num_items=40000000,nodes_init=4,rev_read=True,rev_write=True,sdk_timeout=60,GROUP=P2

    #2GB per vbucket (total vbuckets 64), total documents will be 125000000
    test_basic_create_read,num_items=25000000,nodes_init=4,rev_write=True,rev_read=True,sdk_timeout=60,vbuckets=64,GROUP=P2
    test_basic_create_read,num_items=25000000,nodes_init=4,randomize_doc_size=True,sdk_timeout=60,vbuckets=64,GROUP=P2

    #test with doc_size <=32
    test_basic_create_read,num_items=5000000,nodes_init=1,key_size=12,sdk_timeout=60,vbuckets=4,doc_size=20,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=1,key_size=12,sdk_timeout=60,doc_size=20,GROUP=P2

    #test with doc_size < key_size,
    test_basic_create_read,num_items=25600000,nodes_init=2,key_size=240,sdk_timeout=60,vbuckets=128,doc_size=200,GROUP=P0
    test_basic_create_read,num_items=5000000,nodes_init=2,key_size=22,mix_key_size=True,sdk_timeout=60,vbuckets=16,doc_size=20,GROUP=P1
    test_basic_create_read,num_items=5000000,nodes_init=2,key_size=22,mix_key_size=True,sdk_timeout=60,doc_size=20,GROUP=P2
    test_basic_create_read,num_items=25000000,nodes_init=2,key_size=240,sdk_timeout=60,doc_size=200,GROUP=P2
